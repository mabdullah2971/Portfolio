{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fspLZQ7sJFPn",
    "outputId": "84b6db91-77a2-4a8e-d30a-799a2b1d963a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset contains 17161 rows and 20 columns.\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the Google Sheets CSV export link\n",
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1ioUjhnz6ywSpEbARI-G3RoPyO0NRBqrJnWf-7C_eirs/export?format=csv&id=1ioUjhnz6ywSpEbARI-G3RoPyO0NRBqrJnWf-7C_eirs&gid=1854892322\"\n",
    "\n",
    "# Read the data from the Google Sheets URL into a DataFrame\n",
    "df = pd.read_csv(sheet_url)\n",
    "print('The original dataset contains', df.shape[0], 'rows and', df.shape[1], 'columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Timestamp How old are you?  \\\n",
      "0  4/11/2023 11:02:00            35-44   \n",
      "1  4/11/2023 11:02:07            25-34   \n",
      "2  4/11/2023 11:02:12            35-44   \n",
      "3  4/11/2023 11:02:15            25-34   \n",
      "4  4/11/2023 11:02:25            18-24   \n",
      "\n",
      "                                   Industry  \\\n",
      "0        Government & Public Administration   \n",
      "1  Galleries, Libraries, Archives & Museums   \n",
      "2              Education (Higher Education)   \n",
      "3              Education (Higher Education)   \n",
      "4             Accounting, Banking & Finance   \n",
      "\n",
      "                     Functional area of job                  Job title  \\\n",
      "0              Engineering or Manufacturing         Materials Engineer   \n",
      "1  Galleries, Libraries, Archives & Museums   Assistant Branch Manager   \n",
      "2              Education (Higher Education)  Director of Financial Aid   \n",
      "3        Government & Public Administration   Administrative Assistant   \n",
      "4                            Administration        Executive Assistant   \n",
      "\n",
      "  Job title - additional context  Annual salary (gross)  \\\n",
      "0                            NaN                 125000   \n",
      "1                            NaN                  71000   \n",
      "2                            NaN                  60000   \n",
      "3                            NaN                  42000   \n",
      "4                            NaN                  65000   \n",
      "\n",
      "   Additional monetary compensation Currency Currency - other  \\\n",
      "0                             800.0      USD              NaN   \n",
      "1                               0.0      USD              NaN   \n",
      "2                               0.0      USD              NaN   \n",
      "3                               NaN      USD              NaN   \n",
      "4                               0.0      USD              NaN   \n",
      "\n",
      "  Income - additional context        Country       State            City  \\\n",
      "0                         NaN  United States  California      Ridgecrest   \n",
      "1                         NaN  United States    Virginia  Fairfax County   \n",
      "2                         NaN  United States    Oklahoma       Anadarko    \n",
      "3                         NaN  United States    Virginia        Richmond   \n",
      "4                         NaN  United States        Utah            Orem   \n",
      "\n",
      "  Remote or on-site? Years of experience, overall  \\\n",
      "0            On-site                  11-20 years   \n",
      "1            On-site                   8-10 years   \n",
      "2            On-site                  21-30 years   \n",
      "3            On-site                    2-4 years   \n",
      "4            On-site                    2-4 years   \n",
      "\n",
      "  Years of experience in field Highest level of education completed Gender  \\\n",
      "0                  11-20 years                       College degree    Man   \n",
      "1                    5-7 years                      Master's degree    Man   \n",
      "2                  11-20 years                       College degree  Woman   \n",
      "3                    2-4 years                       College degree    Man   \n",
      "4                    2-4 years                         Some college  Woman   \n",
      "\n",
      "    Race  \n",
      "0  White  \n",
      "1  White  \n",
      "2  White  \n",
      "3  White  \n",
      "4  White  \n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8E6SEfCINCV"
   },
   "source": [
    "## Before analysing any dataset, it needs to be cleaned.\n",
    "Data Cleaning consists of several essential tasks and techniques, including -\n",
    "* Handling missing values\n",
    "* Outlier identification\n",
    "* Data type conversion\n",
    "* Standardization and normalization\n",
    "* Deduplication\n",
    "* Addressing inconsistent data, formatting, typos and spelling errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R996NTm_IkdD"
   },
   "source": [
    "The column names will be renamed to make them more simplified. This is done to make the column names more clean, intuitive and easy to work with during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCcwtLh9JK0f",
    "outputId": "19cdac2b-b5ac-4943-f1b3-7559664d4e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Timestamp\n",
      "1 How old are you?\n",
      "2 Industry\n",
      "3 Functional area of job\n",
      "4 Job title\n",
      "5 Job title - additional context\n",
      "6 Annual salary (gross)\n",
      "7 Additional monetary compensation\n",
      "8 Currency\n",
      "9 Currency - other\n",
      "10 Income - additional context\n",
      "11 Country\n",
      "12 State\n",
      "13 City\n",
      "14 Remote or on-site?\n",
      "15 Years of experience, overall\n",
      "16 Years of experience in field\n",
      "17 Highest level of education completed\n",
      "18 Gender\n",
      "19 Race\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(df.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "GdV4Iq-vOEJv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['submission_date', 'age', 'industry', 'job_function', 'job_title',\n",
      "       'job_title_context', 'annual_salary_gross', 'additional_compensation',\n",
      "       'currency', 'currency_other', 'income_context', 'country', 'us_state',\n",
      "       'city', 'remote_or_onsite', 'experience_overall', 'experience_field',\n",
      "       'education_level', 'gender', 'race'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map old column names to new column names\n",
    "column_renames = {\n",
    "    \"Timestamp\": \"submission_date\",\n",
    "    \"How old are you?\": \"age\",\n",
    "    \"Industry\": \"industry\",\n",
    "    \"Functional area of job\": \"job_function\",\n",
    "    \"Job title\": \"job_title\",\n",
    "    \"Job title - additional context\": \"job_title_context\",\n",
    "    \"Annual salary (gross)\": \"annual_salary_gross\",\n",
    "    \"Additional monetary compensation\": \"additional_compensation\",\n",
    "    \"Currency\": \"currency\",\n",
    "    \"Currency - other\": \"currency_other\",\n",
    "    \"Income - additional context\": \"income_context\",\n",
    "    \"Country\": \"country\",\n",
    "    \"State\": \"us_state\",\n",
    "    \"City\": \"city\",\n",
    "    \"Remote or on-site?\": \"remote_or_onsite\",\n",
    "    \"Years of experience, overall\": \"experience_overall\",\n",
    "    \"Years of experience in field\": \"experience_field\",\n",
    "    \"Highest level of education completed\": \"education_level\",\n",
    "    \"Gender\": \"gender\",\n",
    "    \"Race\": \"race\"\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=column_renames, inplace=True)\n",
    "\n",
    "# Display the renamed DataFrame\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkiS1QvTU8gG",
    "outputId": "7186ff6b-1b64-44ce-9e00-c553cf95ccb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17161 entries, 0 to 17160\n",
      "Data columns (total 20 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   submission_date          17161 non-null  object \n",
      " 1   age                      17161 non-null  object \n",
      " 2   industry                 17115 non-null  object \n",
      " 3   job_function             17050 non-null  object \n",
      " 4   job_title                17161 non-null  object \n",
      " 5   job_title_context        3909 non-null   object \n",
      " 6   annual_salary_gross      17161 non-null  int64  \n",
      " 7   additional_compensation  13145 non-null  float64\n",
      " 8   currency                 17161 non-null  object \n",
      " 9   currency_other           90 non-null     object \n",
      " 10  income_context           1694 non-null   object \n",
      " 11  country                  17161 non-null  object \n",
      " 12  us_state                 14177 non-null  object \n",
      " 13  city                     17093 non-null  object \n",
      " 14  remote_or_onsite         17097 non-null  object \n",
      " 15  experience_overall       17161 non-null  object \n",
      " 16  experience_field         17161 non-null  object \n",
      " 17  education_level          17112 non-null  object \n",
      " 18  gender                   17078 non-null  object \n",
      " 19  race                     17092 non-null  object \n",
      "dtypes: float64(1), int64(1), object(18)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71ZYbRGy2FwM"
   },
   "source": [
    "The 'currency' and 'currency_other' columns can be merged for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VSQ_vwwe3D7u"
   },
   "outputs": [],
   "source": [
    "df['currency'] = np.where(df['currency'] == 'Other', df['currency_other'], df['currency'])\n",
    "df.drop('currency_other', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsBWIjxt4E3G"
   },
   "source": [
    "The entries with null values in the 'industry' column are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qcg4PCxf2jsa"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['industry'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kjtci7UD3vXf"
   },
   "source": [
    "For ease of analysis, I will only keep the entries which contain values from the form checkboxes for the 'industry' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1XcIzTv6AILW"
   },
   "outputs": [],
   "source": [
    "# List of categories to keep\n",
    "categories = ['Accounting, Banking & Finance','Agriculture or Forestry','Art & Design',\n",
    "              'Business or Consulting',\n",
    "              'Computing or Tech',\n",
    "              'Education (Primary/Secondary)','Education (Higher Education)','Engineering or Manufacturing','Entertainment',\n",
    "              'Government and Public Administration',\n",
    "              'Health care','Hospitality & Events',\n",
    "              'Insurance',\n",
    "              'Law','Law Enforcement & Security','Leisure, Sport & Tourism',\n",
    "              'Marketing, Advertising & PR','Media & Digital',\n",
    "              'Nonprofits',\n",
    "              'Property or Construction',\n",
    "              'Recruitment or HR','Retail',\n",
    "              'Sales','Social Work',\n",
    "              'Transport or Logistics',\n",
    "              'Utilities & Telecommunications']\n",
    "\n",
    "# Filter DataFrame to only keep rows with category match\n",
    "df = df[df['industry'].isin(categories)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GOlC2AmI65T"
   },
   "source": [
    "The missing values in the 'additional_compensation' column should be replaced with '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in 'Extra_Compensation' column with 0\n",
    "df.fillna({'additional_compensation': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZj9QmGfMEW_"
   },
   "source": [
    "Entries where 'gender' is not specified will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qvhRDYi8MJuY"
   },
   "outputs": [],
   "source": [
    "# Filter to remove any invalid gender values\n",
    "valid_genders = ['Man', 'Woman', 'Non-binary']\n",
    "df = df[df['gender'].isin(valid_genders)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rfj-daP5Pirv"
   },
   "source": [
    "Entries where 'education_level' is not specified will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IImmNgAuPnbm"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna(subset=['education_level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW0jgSJQQKRb"
   },
   "source": [
    "From entries where 'race' contains the string 'Another option not listed here or prefer not to answer', that specific string is removed from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yc-C4QyeQBrb"
   },
   "outputs": [],
   "source": [
    "# Define the pattern to be removed\n",
    "filter_pattern = re.compile(r'(, )?Another option not listed here or prefer not to answer')\n",
    "\n",
    "# Replace the pattern with an empty string\n",
    "df['race'] = df['race'].str.replace(filter_pattern, '', regex=True)\n",
    "\n",
    "# Drop rows where 'Race' is null or empty\n",
    "df = df.dropna(subset=['race'])\n",
    "df.drop(df[df['race'] == ''].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gs48N9QYxbeX",
    "outputId": "87906897-2687-4dc2-d0fd-14b0c28232ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Asian or Asian American, White',\n",
       "       'Asian or Asian American', 'Hispanic, Latino, or Spanish origin',\n",
       "       'Hispanic, Latino, or Spanish origin, White',\n",
       "       'Black or African American, Middle Eastern or Northern African',\n",
       "       'Black or African American, White', 'Black or African American',\n",
       "       'Middle Eastern or Northern African',\n",
       "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African',\n",
       "       'Native American or Alaska Native, White',\n",
       "       'Black or African American, Native American or Alaska Native, White',\n",
       "       'Asian or Asian American, Black or African American',\n",
       "       'Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
       "       'Middle Eastern or Northern African, White',\n",
       "       'Black or African American, Hispanic, Latino, or Spanish origin',\n",
       "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, White',\n",
       "       'Native American or Alaska Native',\n",
       "       'Asian or Asian American, Hispanic, Latino, or Spanish origin',\n",
       "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White',\n",
       "       'Asian or Asian American, Black or African American, Hispanic, Latino, or Spanish origin, White',\n",
       "       'Black or African American, Middle Eastern or Northern African, White',\n",
       "       'Black or African American, Hispanic, Latino, or Spanish origin, White',\n",
       "       'Asian or Asian American, Black or African American, White',\n",
       "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native',\n",
       "       'Asian or Asian American, Native American or Alaska Native, White',\n",
       "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
       "       'Black or African American, Native American or Alaska Native',\n",
       "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
       "       'Asian or Asian American, Middle Eastern or Northern African',\n",
       "       'Asian or Asian American, Middle Eastern or Northern African, White',\n",
       "       'Black or African American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
       "       'Black or African American, Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, Native American or Alaska Native, White'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4E52Pbv9_N_"
   },
   "source": [
    "The 'annual_salary_gross' and 'additional_compensation' values will be standardized to GBP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iO10WHQE-Pl4"
   },
   "outputs": [],
   "source": [
    "# Average 2023 rates taken from https://www.ofx.com/en-gb/forex-news/historical-exchange-rates/monthly-average-rates/\n",
    "# Took avg of AUD & NZD for AUD/NZD\n",
    "\n",
    "rates = {'USD':0.804368,\n",
    "         'EUR':0.870293,\n",
    "         'JPY':0.005738,\n",
    "         'GBP': 1.0,\n",
    "         'CHF':0.89535,\n",
    "         'CAD':0.595765,\n",
    "         'AUD/NZD':0.514154,\n",
    "         'ZAR': 0.043632,\n",
    "         'HKD':0.102741,\n",
    "         'SEK':0.075851\n",
    "        }\n",
    "\n",
    "# Conversion function\n",
    "def convert_to_gbp(row):\n",
    "    currency = str(row['currency']).upper()\n",
    "    if currency in rates:\n",
    "        row['annual_salary_gross'] *= rates[currency]\n",
    "        row['additional_compensation'] *= rates[currency]\n",
    "        row['currency'] = 'GBP'\n",
    "    return row\n",
    "\n",
    "# Apply the conversion function to the DataFrame\n",
    "df = df.apply(convert_to_gbp, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggOrjgupZOGu"
   },
   "source": [
    "Entries with a 'currency' value other than 'GBP' are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Tid_Emr_Iefv"
   },
   "outputs": [],
   "source": [
    "df = df[df['currency'] == 'GBP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHVJXz3pXeB9"
   },
   "source": [
    "Normalising the 'country' column through the SequenceMatcher imported from the difflib library. A function is created which is used to compare the similarity ratios between each value in the 'country' column and the values in the 'correct_names' array. This 'correct_names' array contains the correct names of all the countries.\n",
    "\n",
    "Note that this method isn't 100% accurate but it is efficient. With large datasets, it is not possible to go through each entry to normalise the values in a specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HM70JQI5kBEc"
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "df['country'] = df['country'].str.replace('.', '', regex=False) # remove periods\n",
    "\n",
    "#let's specify correct country names\n",
    "country_names = {\"Afghanistan\",\"Albania\",\"Algeria\",\"Andorra\",\"Angola\",\"Anguilla\",\"Antigua & Barbuda\",\"Argentina\",\"Armenia\",\"Aruba\",\"Australia\",\n",
    "                 \"Austria\",\"Azerbaijan\",\n",
    "                 \"Bahamas\",\"Bahrain\",\"Bangladesh\",\"Barbados\",\"Belarus\",\"Belgium\",\"Belize\",\"Benin\",\"Bermuda\",\"Bhutan\",\"Bolivia\",\n",
    "                 \"Bosnia & Herzegovina\",\"Botswana\",\"Brazil\",\"British Virgin Islands\",\"Brunei\",\"Bulgaria\",\"Burkina Faso\",\"Burundi\",\n",
    "                 \"Cambodia\",\"Cameroon\",\"Cape Verde\",\"Cayman Islands\",\"Chad\",\"Chile\",\"China\",\"Colombia\",\"Congo\",\"Cook Islands\",\"Costa Rica\",\n",
    "                 \"Cote D Ivoire\",\"Croatia\",\"Cuba\",\"Cyprus\",\"Czech Republic\",\n",
    "                 \"Denmark\",\"Djibouti\",\"Dominica\",\"Dominican Republic\",\n",
    "                 \"England\",\"Ecuador\",\"Egypt\",\"El Salvador\",\"Equatorial Guinea\",\"Estonia\",\"Ethiopia\",\n",
    "                 \"Falkland Islands\",\"Faroe Islands\",\"Fiji\",\"Finland\",\"France\",\"French Polynesia\",\"French West Indies\",\n",
    "                 \"Gabon\",\"Gambia\",\"Georgia\",\"Germany\",\"Ghana\",\"Gibraltar\",\"Greece\",\"Greenland\",\"Grenada\",\"Guam\",\"Guatemala\",\"Guernsey\",\"Guinea\",\n",
    "                 \"Guinea Bissau\",\"Guyana\",\n",
    "                 \"Haiti\",\"Honduras\",\"Hong Kong\",\"Hungary\",\n",
    "                 \"Iceland\",\"India\",\"Indonesia\",\"Iran\",\"Iraq\",\"Ireland\",\"Isle of Man\",\"Israel\",\"Italy\",\n",
    "                 \"Jamaica\",\"Japan\",\"Jersey\",\"Jordan\",\n",
    "                 \"Kazakhstan\",\"Kenya\",\"Kuwait\",\"Kyrgyz Republic\",\n",
    "                 \"Laos\",\"Latvia\",\"Lebanon\",\"Lesotho\",\"Liberia\",\"Libya\",\"Liechtenstein\",\"Lithuania\",\"Luxembourg\",\n",
    "                 \"Macau\",\"Macedonia\",\"Madagascar\",\"Malawi\",\"Malaysia\",\"Maldives\",\"Mali\",\"Malta\",\"Mauritania\",\"Mauritius\",\"Mexico\",\"Moldova\",\n",
    "                 \"Monaco\",\"Mongolia\",\"Montenegro\",\"Montserrat\",\"Morocco\",\"Mozambique\",\n",
    "                 \"Northen Ireland\",\"Namibia\",\"Nepal\",\"Netherlands\",\"Netherlands Antilles\",\"New Caledonia\",\"New Zealand\",\"Nicaragua\",\"Niger\",\n",
    "                 \"Nigeria\",\"Norway\",\n",
    "                 \"Oman\",\n",
    "                 \"Pakistan\",\"Palestine\",\"Panama\",\"Papua New Guinea\",\"Paraguay\",\"Peru\",\"Philippines\",\"Poland\",\"Portugal\",\"Puerto Rico\",\n",
    "                 \"Qatar\",\n",
    "                 \"Reunion\",\"Romania\",\"Russia\",\"Rwanda\",\n",
    "                 \"Scotland\",\"Saint Pierre & Miquelon\",\"Samoa\",\"San Marino\",\"Satellite\",\"Saudi Arabia\",\"Senegal\",\"Serbia\",\"Seychelles\",\n",
    "                 \"Sierra Leone\", \"Singapore\",\"Slovakia\",\"Slovenia\",\"South Africa\",\"South Korea\",\"Spain\",\"Sri Lanka\",\"St Kitts & Nevis\",\n",
    "                 \"St Lucia\",\"St Vincent\",\"St. Lucia\",\"Sudan\",\"Suriname\",\"Swaziland\",\"Sweden\",\"Switzerland\",\"Syria\",\n",
    "                 \"Taiwan\",\"Tajikistan\",\"Tanzania\",\"Thailand\",\"Timor L'Este\",\"Togo\",\"Tonga\",\"Trinidad & Tobago\",\"Tunisia\",\"Turkey\",\n",
    "                 \"Turkmenistan\",\"Turks & Caicos\",\n",
    "                 \"Uganda\",\"Ukraine\",\"United Arab Emirates\",\"United Kingdom\",\"UK\",\"United States\",\"USA\",\"Uruguay\",\"Uzbekistan\",\n",
    "                 \"Venezuela\",\"Vietnam\",\"US Virgin Islands\",\n",
    "                 \"Wales\",\n",
    "                 \"Yemen\",\n",
    "                 \"Zambia\",\"Zimbabwe\"};\n",
    "\n",
    "#let's specify the function that select the most similar word\n",
    "def get_most_similar(word,wordlist):\n",
    "  top_similarity = 0.25 # set to 0.25 to ensure some similarity\n",
    "  most_similar_word = word\n",
    "  for candidate in wordlist:\n",
    "    similarity = SequenceMatcher(None,word.lower(),candidate.lower()).ratio()\n",
    "    if similarity > top_similarity:\n",
    "      top_similarity = similarity\n",
    "      most_similar_word = candidate\n",
    "\n",
    "  return most_similar_word\n",
    "\n",
    "#now apply this function over 'country' column in dataframe\n",
    "df['country'] = df['country'].apply(lambda x: get_most_similar(x, country_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7PSW4Vz4nFs"
   },
   "source": [
    "After checking the unique values in the 'country' column, there are some values that can be grouped up. There are also a few instances of the wrong information being entered. These entries need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DZA3S6mnWbg",
    "outputId": "a3d085e4-6db3-488b-ba8e-23bbf5fe9a97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United States',\n",
       " 'Panama',\n",
       " 'United Kingdom',\n",
       " 'Ireland',\n",
       " 'France',\n",
       " 'Austria',\n",
       " 'Germany',\n",
       " 'Sweden',\n",
       " 'South Africa',\n",
       " 'Australia',\n",
       " 'Montserrat',\n",
       " 'Belgium',\n",
       " 'Spain',\n",
       " 'United States, I physically work in the US but my programs are focused on foreign youth abroad',\n",
       " 'Netherlands',\n",
       " 'Mexico',\n",
       " 'Isle of Man',\n",
       " 'Japan',\n",
       " 'Egypt',\n",
       " 'Finland',\n",
       " 'China',\n",
       " 'Malta',\n",
       " 'Croatia',\n",
       " 'Armenia',\n",
       " 'Luxembourg',\n",
       " 'Latvia',\n",
       " 'French Polynesia',\n",
       " 'New Zealand',\n",
       " 'Italy',\n",
       " 'Portugal',\n",
       " 'Saudi Arabia',\n",
       " 'Brazil',\n",
       " 'Fully remote - currently employed by US company living in UK',\n",
       " 'Maldives',\n",
       " 'Hungary',\n",
       " 'New Caledonia',\n",
       " 'Switzerland',\n",
       " 'Cayman Islands',\n",
       " 'Gambia',\n",
       " 'Mongolia',\n",
       " 'Hong Kong',\n",
       " 'Kenya',\n",
       " 'United Arab Emirates',\n",
       " 'Denmark',\n",
       " 'India',\n",
       " 'Burkina Faso',\n",
       " 'Israel',\n",
       " 'Slovenia',\n",
       " 'Poland',\n",
       " 'Tanzania',\n",
       " 'Singapore',\n",
       " 'USA',\n",
       " 'Bulgaria',\n",
       " 'Netherlands Antilles',\n",
       " 'Greece',\n",
       " 'Norway']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = df['country'].unique().tolist()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BopNxeT12eZh"
   },
   "outputs": [],
   "source": [
    "country_mapping = {\n",
    "    'United States': 'USA',\n",
    "    'United Kingdom': 'UK'\n",
    "}\n",
    "\n",
    "# Use the `replace` method to replace values in the 'Country' column\n",
    "df['country'] = df['country'].replace(country_mapping, regex=False)\n",
    "\n",
    "# Removing entries that have irrelevant information in the 'Country' column\n",
    "df = df[df['country'].str.len() <= 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwDEl0VY3Pgt"
   },
   "source": [
    "Entries have been removed and so the dataframe's index should be reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "db8IimN_4-Hr"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqxK2vJxeka7"
   },
   "source": [
    "Certain columns are dropped as they are not needed for our analysis. These columns are not essential for achieving the specified objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JdjlimFme-T5"
   },
   "outputs": [],
   "source": [
    "df.drop('age', axis=1, inplace=True)\n",
    "df.drop('job_title_context', axis=1, inplace=True)\n",
    "df.drop('income_context', axis=1, inplace=True)\n",
    "df.drop('us_state', axis=1, inplace=True)\n",
    "df.drop('experience_overall', axis=1, inplace=True) # unnecessary as 'Field_Experience' is more relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oODar7kM6nE4"
   },
   "source": [
    "I've then exported the clean dataframe to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Rt50DUMs55_b"
   },
   "outputs": [],
   "source": [
    "df.to_csv('clean_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
